{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ4Txe8fQvk9sOww7ZFtvm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jijnash22/multimodal-parkinsons-ai/blob/main/notebooks/01_voice_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "a1fc6e5e",
        "outputId": "c5bf0173-4bb4-4fb8-d26f-452f67cfbaed"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-17cd2130-c7be-422c-921d-564cf92eddcf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-17cd2130-c7be-422c-921d-564cf92eddcf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving voice_dataset.zip to voice_dataset.zip\n",
            "User uploaded file \"voice_dataset.zip\" with length 4261535 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir(\"/content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxb2_rWaOSy7",
        "outputId": "c20c3c6b-41bb-4103-d89e-95ccb69e874b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'voice_dataset.zip', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip voice_dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWFeQMiwOX1f",
        "outputId": "142dfacf-f972-4560-9064-4d25e041d2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  voice_dataset.zip\n",
            "   creating: voice_dataset/\n",
            "   creating: voice_dataset/HC/\n",
            "   creating: voice_dataset/HC/HC_AH/\n",
            "  inflating: voice_dataset/HC/HC_AH/AH_064F_7AB034C9-72E4-438B-A9B3-AD7FDA1596C5.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_114S_A89F3548-0B61-4770-B800-2E26AB3908B6.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_121A_BD5BA248-E807-4CB9-8B53-47E7FFE5F8E2.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_123G_559F0706-2238-447C-BA39-DB5933BA619D.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_195B_39DA6A45-F4CC-492A-80D4-FB79049ACC22.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_197T_7552379A-2310-46E1-9466-9D8045C990B8.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_222K_FC9D2763-1836-460B-954F-37F23D6CD81D.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_264Z_593C20CD-0A54-4177-B031-26EE147080A3.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_292J_201CB911-31C1-4CD0-BD73-4FBA4A16C21F.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_322A_C3BF5535-A11E-498E-94EB-BE7E74099FFB.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_325A_3EB21DC7-C340-4D0E-AC9E-0EABF217BBEE.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_325J_7F5F27AA-5A93-43CF-AB17-FC53940BF4B0.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_333L_6C551A6E-CC47-410E-AA49-2DC0A86E6489.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_378G_3C2A05CE-36E4-4956-8FC2-0494B27D3EA8.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_420J_07C96C2C-6E96-4A2F-BEC9-5CB71DB309B6.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_444B_E1586F09-1BF5-408D-A55E-96D9E8B76A43.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_456K_CBF60DD0-82AA-430E-A5E9-E1D3AE175CCB.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_469Z_5BB05B2C-39C4-434D-9445-244E7580F840.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_473R_E4947FD3-23C1-44F1-BCE4-DC59D8269FDE.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_501F_4BDDBB93-EA99-4B1C-AD7F-4D874F39FB0C.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_511K_DDC6D065-56B3-436B-9D08-73326C791B69.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_523T_66147C3C-938A-4CF9-913E-5D49D72BD8B6.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_528T_6A746E6E-FB60-4363-842F-A7368A1E5B2C.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_538M_AE709CB7-1123-47F8-8BD2-000158BDBC01.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_562E_151814F5-BB0F-44EF-9A22-FE2862FC3411.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_569E_B26CCA1E-29AD-48DD-9947-48DB8A56CA31.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_596S_BBE9779F-C440-42D3-9C96-4CD6121D1F7E.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_619B_5CF9C4CA-31AA-4F22-8E57-8E53618CC224.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_621N_204CF3E2-1DA0-4908-A47F-78997B1BAFC2.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_667J_605FB4D5-E0DB-4B9B-8F58-784561C51693.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_678A_2E7AFA48-34C1-4DAD-A73C-95F7ABF6B138.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_743R_66BD23F9-D685-4315-86F8-7697B5084F7B.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_753G_073DCC32-4397-4719-A019-DDD41F30F5F1.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_777G_4C8ACC89-7FE2-4174-AE3A-B21B39A0C869.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_777R_A36CF7FA-37FD-483E-98FE-040942B1DF49.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_789Y_20CB672C-5F66-425E-8707-BE5B7FF807E2.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_803T_66094C40-AE64-4AD3-AA97-B052C69DA3EF.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_821C_8F9D5EF0-18B2-4967-B36D-82E014792BC3.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_888A_7F1444B0-B12C-4B55-AF2A-463395DCAF3C.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_904H_85B22FC1-BA09-4A17-A374-B00B2445CD27.wav  \n",
            "  inflating: voice_dataset/HC/HC_AH/AH_942A_3F7867F3-1AE2-4BE6-B5EC-AC3157D310CF.wav  \n",
            "   creating: voice_dataset/PD/\n",
            "   creating: voice_dataset/PD/PD_AH/\n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545616858-3A749CBC-3FEB-4D35-820E-E45C3E5B9B6A.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545622717-461DFFFE-54AF-42AF-BA78-528BD505D624.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545622718-C052AD58-5E6B-4ADC-855C-F76B66BAFA6E.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545622719-52C23861-6E0D-41E0-A3D8-9358C28C019B.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545622720-E1486AF6-8C95-47EB-829B-4D62698C987A.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545622722-3C79DA68-36BB-43A2-B29C-61AEF480E07E.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545629296-C2C009C6-8C17-42EA-B6BE-362942FC4692.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545643618-82A143AC-B643-4273-A923-C42A83AEEC5F.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545648867-CB17D873-1CEA-492A-B5B0-93C7463F516C.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545692309-EA8C4DC0-9B2A-4CC7-A490-851A2129A733.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545692315-C2972597-9AEC-4060-A186-F1F59340640C.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545713221-1E77C030-4558-4A88-B1A2-6AB777ACAE61.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545713222-DA13DC3A-F24B-454E-984F-19DF19328D39.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545713223-E6D59EE5-4C3F-4B40-AE8F-0657EF94DB66.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545713224-1B3708B0-8792-4FEE-B03B-C7CB9CB03D58.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545743929-E2EAE1A3-7E46-4DCF-8DB7-37A5CA47DB9D.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545753013-FCFF8F46-08FF-4C87-B443-D2039E5DA945.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545753014-C68926CC-AB91-49AF-90A6-BB5C434283DB.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545753015-58CAA743-BA9A-47E0-B9EF-CC35E9EFB839.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789668-A4F6069C-5E1A-49F5-9EDC-59C6EB833E42.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789670-C297FD53-BF71-4183-86A0-58E5E1EB0DF8.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789671-794D2256-DDFF-4009-8BA8-8A306C8FA14F.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789674-53885025-35F1-48C1-9826-BAAEB8BEAF58.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789675-243F18DB-4432-4C87-B12C-6EEC2D2D30D6.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789677-D381D801-B073-4945-BE0D-E250126EA6B1.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789680-7FF9D4F1-DDCC-4CB6-8668-76530D670FA5.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789682-7554E0C7-4E25-49C3-9E6C-04D525455E28.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545789690-DA26461A-AF40-4A43-9662-3A93EE872359.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545806325-8A17002B-CFD3-4DCF-8854-04F0F2BFF21B.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545806326-BD0FE665-1AD5-4F55-8342-0FAB8B15680B.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545812844-DFBCDA22-CADB-444A-9623-16A39D45E9E7.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545812846-0C14B32A-6C50-4B62-BC89-0A815C2DEEFA.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545834603-857E007F-1CCF-4249-8160-3A0F3F5AB58D.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545841221-6FC57E6E-65B6-4859-A15A-55856D7E75C0.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545841222-DE5AEF27-7F4E-45A4-BF7D-9E87E7A786AE.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545841223-24FB0419-5BAE-4F9C-8EBC-CD62DA6590D2.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545841226-C699FC9E-1E0C-474D-A12A-936DD92B8980.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545841227-5C77713A-66F1-49D0-BC8A-702C152E668D.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545847410-D1BA3BB4-1F61-44CA-ACDE-455A8E97E04B.wav  \n",
            "  inflating: voice_dataset/PD/PD_AH/AH_545880204-EE87D3E2-0D4C-4EAA-ACD7-C3F177AFF62F.wav  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at0XSdnMOYYc",
        "outputId": "c7f553e3-54de-45c4-fa96-1d2dcea1b832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'voice_dataset.zip', 'voice_dataset', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/voice_dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXrnluxkPRLJ",
        "outputId": "2f078a22-886c-4ad1-dc57-278dd9d89101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PD', 'HC']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/voice_dataset/HC\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DXI7jHkPU5H",
        "outputId": "c32ea003-7afe-4276-866a-7e5edb893a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HC_AH']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/voice_dataset/HC/HC_AH\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsau27EDPjdD",
        "outputId": "3fa41716-3972-4c50-8ca3-00633c8a2363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AH_904H_85B22FC1-BA09-4A17-A374-B00B2445CD27.wav',\n",
              " 'AH_114S_A89F3548-0B61-4770-B800-2E26AB3908B6.wav',\n",
              " 'AH_569E_B26CCA1E-29AD-48DD-9947-48DB8A56CA31.wav',\n",
              " 'AH_528T_6A746E6E-FB60-4363-842F-A7368A1E5B2C.wav',\n",
              " 'AH_292J_201CB911-31C1-4CD0-BD73-4FBA4A16C21F.wav',\n",
              " 'AH_469Z_5BB05B2C-39C4-434D-9445-244E7580F840.wav',\n",
              " 'AH_325A_3EB21DC7-C340-4D0E-AC9E-0EABF217BBEE.wav',\n",
              " 'AH_803T_66094C40-AE64-4AD3-AA97-B052C69DA3EF.wav',\n",
              " 'AH_473R_E4947FD3-23C1-44F1-BCE4-DC59D8269FDE.wav',\n",
              " 'AH_562E_151814F5-BB0F-44EF-9A22-FE2862FC3411.wav',\n",
              " 'AH_821C_8F9D5EF0-18B2-4967-B36D-82E014792BC3.wav',\n",
              " 'AH_678A_2E7AFA48-34C1-4DAD-A73C-95F7ABF6B138.wav',\n",
              " 'AH_596S_BBE9779F-C440-42D3-9C96-4CD6121D1F7E.wav',\n",
              " 'AH_222K_FC9D2763-1836-460B-954F-37F23D6CD81D.wav',\n",
              " 'AH_942A_3F7867F3-1AE2-4BE6-B5EC-AC3157D310CF.wav',\n",
              " 'AH_789Y_20CB672C-5F66-425E-8707-BE5B7FF807E2.wav',\n",
              " 'AH_378G_3C2A05CE-36E4-4956-8FC2-0494B27D3EA8.wav',\n",
              " 'AH_777G_4C8ACC89-7FE2-4174-AE3A-B21B39A0C869.wav',\n",
              " 'AH_444B_E1586F09-1BF5-408D-A55E-96D9E8B76A43.wav',\n",
              " 'AH_777R_A36CF7FA-37FD-483E-98FE-040942B1DF49.wav',\n",
              " 'AH_195B_39DA6A45-F4CC-492A-80D4-FB79049ACC22.wav',\n",
              " 'AH_501F_4BDDBB93-EA99-4B1C-AD7F-4D874F39FB0C.wav',\n",
              " 'AH_621N_204CF3E2-1DA0-4908-A47F-78997B1BAFC2.wav',\n",
              " 'AH_123G_559F0706-2238-447C-BA39-DB5933BA619D.wav',\n",
              " 'AH_325J_7F5F27AA-5A93-43CF-AB17-FC53940BF4B0.wav',\n",
              " 'AH_743R_66BD23F9-D685-4315-86F8-7697B5084F7B.wav',\n",
              " 'AH_667J_605FB4D5-E0DB-4B9B-8F58-784561C51693.wav',\n",
              " 'AH_511K_DDC6D065-56B3-436B-9D08-73326C791B69.wav',\n",
              " 'AH_064F_7AB034C9-72E4-438B-A9B3-AD7FDA1596C5.wav',\n",
              " 'AH_197T_7552379A-2310-46E1-9466-9D8045C990B8.wav',\n",
              " 'AH_264Z_593C20CD-0A54-4177-B031-26EE147080A3.wav',\n",
              " 'AH_456K_CBF60DD0-82AA-430E-A5E9-E1D3AE175CCB.wav',\n",
              " 'AH_121A_BD5BA248-E807-4CB9-8B53-47E7FFE5F8E2.wav',\n",
              " 'AH_619B_5CF9C4CA-31AA-4F22-8E57-8E53618CC224.wav',\n",
              " 'AH_538M_AE709CB7-1123-47F8-8BD2-000158BDBC01.wav',\n",
              " 'AH_753G_073DCC32-4397-4719-A019-DDD41F30F5F1.wav',\n",
              " 'AH_333L_6C551A6E-CC47-410E-AA49-2DC0A86E6489.wav',\n",
              " 'AH_322A_C3BF5535-A11E-498E-94EB-BE7E74099FFB.wav',\n",
              " 'AH_523T_66147C3C-938A-4CF9-913E-5D49D72BD8B6.wav',\n",
              " 'AH_420J_07C96C2C-6E96-4A2F-BEC9-5CB71DB309B6.wav',\n",
              " 'AH_888A_7F1444B0-B12C-4B55-AF2A-463395DCAF3C.wav']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/voice_dataset\"\n"
      ],
      "metadata": {
        "id": "TYZE7R4MStZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for f in files:\n",
        "        if f.endswith(\".wav\"):\n",
        "            count += 1\n",
        "            print(os.path.join(root, f))\n",
        "\n",
        "print(\"Total wav files found:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz_N5bfeS3_g",
        "outputId": "3c44b519-38f7-4774-9e3a-55401f8a2618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/voice_dataset/PD/PD_AH/AH_545643618-82A143AC-B643-4273-A923-C42A83AEEC5F.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545622718-C052AD58-5E6B-4ADC-855C-F76B66BAFA6E.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545880204-EE87D3E2-0D4C-4EAA-ACD7-C3F177AFF62F.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545812846-0C14B32A-6C50-4B62-BC89-0A815C2DEEFA.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545622719-52C23861-6E0D-41E0-A3D8-9358C28C019B.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545847410-D1BA3BB4-1F61-44CA-ACDE-455A8E97E04B.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545648867-CB17D873-1CEA-492A-B5B0-93C7463F516C.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545713221-1E77C030-4558-4A88-B1A2-6AB777ACAE61.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545834603-857E007F-1CCF-4249-8160-3A0F3F5AB58D.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545622722-3C79DA68-36BB-43A2-B29C-61AEF480E07E.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545713223-E6D59EE5-4C3F-4B40-AE8F-0657EF94DB66.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545616858-3A749CBC-3FEB-4D35-820E-E45C3E5B9B6A.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545753013-FCFF8F46-08FF-4C87-B443-D2039E5DA945.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545806326-BD0FE665-1AD5-4F55-8342-0FAB8B15680B.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545622717-461DFFFE-54AF-42AF-BA78-528BD505D624.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545622720-E1486AF6-8C95-47EB-829B-4D62698C987A.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545753015-58CAA743-BA9A-47E0-B9EF-CC35E9EFB839.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789668-A4F6069C-5E1A-49F5-9EDC-59C6EB833E42.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545841221-6FC57E6E-65B6-4859-A15A-55856D7E75C0.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789677-D381D801-B073-4945-BE0D-E250126EA6B1.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545692315-C2972597-9AEC-4060-A186-F1F59340640C.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789670-C297FD53-BF71-4183-86A0-58E5E1EB0DF8.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789680-7FF9D4F1-DDCC-4CB6-8668-76530D670FA5.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545841222-DE5AEF27-7F4E-45A4-BF7D-9E87E7A786AE.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545806325-8A17002B-CFD3-4DCF-8854-04F0F2BFF21B.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789675-243F18DB-4432-4C87-B12C-6EEC2D2D30D6.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545713222-DA13DC3A-F24B-454E-984F-19DF19328D39.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545713224-1B3708B0-8792-4FEE-B03B-C7CB9CB03D58.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545743929-E2EAE1A3-7E46-4DCF-8DB7-37A5CA47DB9D.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789690-DA26461A-AF40-4A43-9662-3A93EE872359.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545692309-EA8C4DC0-9B2A-4CC7-A490-851A2129A733.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545629296-C2C009C6-8C17-42EA-B6BE-362942FC4692.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545753014-C68926CC-AB91-49AF-90A6-BB5C434283DB.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789671-794D2256-DDFF-4009-8BA8-8A306C8FA14F.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545841226-C699FC9E-1E0C-474D-A12A-936DD92B8980.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545841227-5C77713A-66F1-49D0-BC8A-702C152E668D.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789682-7554E0C7-4E25-49C3-9E6C-04D525455E28.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545841223-24FB0419-5BAE-4F9C-8EBC-CD62DA6590D2.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545789674-53885025-35F1-48C1-9826-BAAEB8BEAF58.wav\n",
            "/content/voice_dataset/PD/PD_AH/AH_545812844-DFBCDA22-CADB-444A-9623-16A39D45E9E7.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_904H_85B22FC1-BA09-4A17-A374-B00B2445CD27.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_114S_A89F3548-0B61-4770-B800-2E26AB3908B6.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_569E_B26CCA1E-29AD-48DD-9947-48DB8A56CA31.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_528T_6A746E6E-FB60-4363-842F-A7368A1E5B2C.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_292J_201CB911-31C1-4CD0-BD73-4FBA4A16C21F.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_469Z_5BB05B2C-39C4-434D-9445-244E7580F840.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_325A_3EB21DC7-C340-4D0E-AC9E-0EABF217BBEE.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_803T_66094C40-AE64-4AD3-AA97-B052C69DA3EF.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_473R_E4947FD3-23C1-44F1-BCE4-DC59D8269FDE.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_562E_151814F5-BB0F-44EF-9A22-FE2862FC3411.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_821C_8F9D5EF0-18B2-4967-B36D-82E014792BC3.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_678A_2E7AFA48-34C1-4DAD-A73C-95F7ABF6B138.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_596S_BBE9779F-C440-42D3-9C96-4CD6121D1F7E.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_222K_FC9D2763-1836-460B-954F-37F23D6CD81D.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_942A_3F7867F3-1AE2-4BE6-B5EC-AC3157D310CF.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_789Y_20CB672C-5F66-425E-8707-BE5B7FF807E2.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_378G_3C2A05CE-36E4-4956-8FC2-0494B27D3EA8.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_777G_4C8ACC89-7FE2-4174-AE3A-B21B39A0C869.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_444B_E1586F09-1BF5-408D-A55E-96D9E8B76A43.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_777R_A36CF7FA-37FD-483E-98FE-040942B1DF49.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_195B_39DA6A45-F4CC-492A-80D4-FB79049ACC22.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_501F_4BDDBB93-EA99-4B1C-AD7F-4D874F39FB0C.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_621N_204CF3E2-1DA0-4908-A47F-78997B1BAFC2.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_123G_559F0706-2238-447C-BA39-DB5933BA619D.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_325J_7F5F27AA-5A93-43CF-AB17-FC53940BF4B0.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_743R_66BD23F9-D685-4315-86F8-7697B5084F7B.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_667J_605FB4D5-E0DB-4B9B-8F58-784561C51693.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_511K_DDC6D065-56B3-436B-9D08-73326C791B69.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_064F_7AB034C9-72E4-438B-A9B3-AD7FDA1596C5.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_197T_7552379A-2310-46E1-9466-9D8045C990B8.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_264Z_593C20CD-0A54-4177-B031-26EE147080A3.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_456K_CBF60DD0-82AA-430E-A5E9-E1D3AE175CCB.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_121A_BD5BA248-E807-4CB9-8B53-47E7FFE5F8E2.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_619B_5CF9C4CA-31AA-4F22-8E57-8E53618CC224.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_538M_AE709CB7-1123-47F8-8BD2-000158BDBC01.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_753G_073DCC32-4397-4719-A019-DDD41F30F5F1.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_333L_6C551A6E-CC47-410E-AA49-2DC0A86E6489.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_322A_C3BF5535-A11E-498E-94EB-BE7E74099FFB.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_523T_66147C3C-938A-4CF9-913E-5D49D72BD8B6.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_420J_07C96C2C-6E96-4A2F-BEC9-5CB71DB309B6.wav\n",
            "/content/voice_dataset/HC/HC_AH/AH_888A_7F1444B0-B12C-4B55-AF2A-463395DCAF3C.wav\n",
            "Total wav files found: 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP4gjuRoS580",
        "outputId": "2851dc57-37f9-4036-8879-9f812de0d9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "project_dir = \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project\"\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "print(\"Project directory ready:\", project_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXNXWwq_Tq04",
        "outputId": "ff4e3017-5862-4f0e-ec8b-be827e9f5d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project directory ready: /content/drive/MyDrive/IIIT_Nagpur_PD_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in [\"data\", \"notebooks\", \"features\", \"models\"]:\n",
        "    os.makedirs(os.path.join(project_dir, folder), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "n9nJg-ttUMth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/voice_dataset /content/drive/MyDrive/IIIT_Nagpur_PD_Project/data/\n"
      ],
      "metadata": {
        "id": "onbLPWeLUUNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBKdanJtUXly",
        "outputId": "298ba3c3-b94f-4cce-9bf5-77cccdde916b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['voice_dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/data/voice_dataset\"\n"
      ],
      "metadata": {
        "id": "qnLSs6HhUaQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praat-parselmouth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXrYMXjoUwEn",
        "outputId": "c79cdab9-0f49-427d-abe4-c287e2db8c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from praat-parselmouth) (2.0.2)\n",
            "Downloading praat_parselmouth-0.4.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "\n",
        "print(\"All imports successful\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3g7XjBgU44n",
        "outputId": "d04a3cb4-4dca-423c-9c6f-dabb427b41af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smjbqJG9VK7W",
        "outputId": "075ceefb-9d6b-4ea4-9f9b-fe6754c54218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "\n",
        "print(\"Imports OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S9lJ_D7VT00",
        "outputId": "3c769858-91e5-405d-9571-3a7131e66510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/data/voice_dataset\"\n"
      ],
      "metadata": {
        "id": "5ussfmeRVZP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(audio, sr, n_mfcc=13):\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    return np.hstack([np.mean(mfcc, axis=1), np.var(mfcc, axis=1)])\n",
        "\n",
        "def extract_pitch(audio, sr):\n",
        "    pitch = librosa.yin(audio, fmin=75, fmax=300, sr=sr)\n",
        "    pitch = pitch[pitch > 0]\n",
        "    return np.mean(pitch) if len(pitch) > 0 else 0\n",
        "\n",
        "def extract_jitter_shimmer(audio_path):\n",
        "    sound = parselmouth.Sound(audio_path)\n",
        "    pp = call(sound, \"To PointProcess (periodic, cc)\", 75, 300)\n",
        "    jitter = call(pp, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "    shimmer = call([sound, pp], \"Get shimmer (local)\",\n",
        "                    0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "    return jitter, shimmer\n",
        "\n",
        "def extract_voice_features(audio, sr, audio_path):\n",
        "    mfcc = extract_mfcc(audio, sr)\n",
        "    pitch = extract_pitch(audio, sr)\n",
        "    jitter, shimmer = extract_jitter_shimmer(audio_path)\n",
        "    return np.hstack([mfcc, pitch, jitter, shimmer])\n"
      ],
      "metadata": {
        "id": "DdnqxtePVbaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_features = []\n",
        "y_labels = []\n",
        "\n",
        "for label, class_name in enumerate([\"HC\", \"PD\"]):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "\n",
        "    for root, _, files in os.walk(class_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".wav\"):\n",
        "                file_path = os.path.join(root, file)\n",
        "\n",
        "                audio, sr = librosa.load(file_path, sr=16000, mono=True)\n",
        "                audio, _ = librosa.effects.trim(audio)\n",
        "\n",
        "                features = extract_voice_features(audio, sr, file_path)\n",
        "\n",
        "                X_features.append(features)\n",
        "                y_labels.append(label)\n",
        "\n",
        "X_features = np.array(X_features)\n",
        "y_labels = np.array(y_labels)\n",
        "\n",
        "print(\"Extraction done\")\n",
        "print(X_features.shape, y_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzGM4VGBVhhD",
        "outputId": "a5e22552-8543-456c-92ff-09f36cd4c5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction done\n",
            "(81, 29) (81,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLhs_FtGVjwm",
        "outputId": "2720c60d-bd48-4561-db97-ebd72b336e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(81, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_features.npy\", X_features)\n",
        "np.save(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/y_labels.npy\", y_labels)\n",
        "\n",
        "print(\"Features saved successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q_cbekIVtIB",
        "outputId": "467caf8c-808a-4929-ccb0-6af025c16a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "8rneFuL5VvJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_features = np.load(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_features.npy\")\n",
        "y_labels = np.load(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/y_labels.npy\")\n",
        "\n",
        "print(X_features.shape, y_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo2yQwoFV8Pe",
        "outputId": "bb08a8fa-1340-42f5-f329-69897f905fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(81, 29) (81,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_normalized = scaler.fit_transform(X_features)\n",
        "\n",
        "print(\"Normalization complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LohcNoSZV-BJ",
        "outputId": "b92a3928-c560-4438-c35b-2ad2f4e0b1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean (approx):\", np.mean(X_normalized, axis=0)[:5])\n",
        "print(\"Std (approx):\", np.std(X_normalized, axis=0)[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsJrN8dWA7-",
        "outputId": "1ce61151-20df-43e5-902a-bbde289b56d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean (approx): [-2.38492353e-16 -1.00057137e-16  3.04283347e-16  5.78241159e-17\n",
            "  1.13763594e-16]\n",
            "Std (approx): [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_normalized.npy\", X_normalized)\n"
      ],
      "metadata": {
        "id": "66MMPQ_cWESy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(\n",
        "    scaler,\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/standard_scaler.pkl\"\n",
        ")\n",
        "\n",
        "print(\"Normalized features and scaler saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hadfRi1cWIde",
        "outputId": "8643d78c-de84-45c0-b515-434c282810fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized features and scaler saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "sH-f0HUQWKxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_normalized.npy\")\n",
        "y = np.load(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/y_labels.npy\")\n",
        "\n",
        "n_features = X.shape[1]\n",
        "print(\"Number of features:\", n_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypi118IvWcCm",
        "outputId": "7b2bc435-1787-40c9-a632-9ecab44c9fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_function(weights):\n",
        "    # Apply feature weights\n",
        "    X_weighted = X * weights\n",
        "\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    # 5-fold cross-validation accuracy\n",
        "    scores = cross_val_score(model, X_weighted, y, cv=5, scoring='accuracy')\n",
        "\n",
        "    # PSO minimizes → so return negative accuracy\n",
        "    return -np.mean(scores)\n"
      ],
      "metadata": {
        "id": "BMjKF_UxWd6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_particles = 20\n",
        "n_iterations = 30\n",
        "\n",
        "# Initialize particles\n",
        "particles = np.random.rand(n_particles, n_features)\n",
        "velocities = np.zeros_like(particles)\n",
        "\n",
        "# Personal & global best\n",
        "pbest = particles.copy()\n",
        "pbest_scores = np.array([fitness_function(p) for p in particles])\n",
        "\n",
        "gbest = pbest[np.argmin(pbest_scores)]\n",
        "gbest_score = np.min(pbest_scores)\n",
        "\n",
        "# PSO parameters\n",
        "w = 0.5    # inertia\n",
        "c1 = 1.5   # cognitive\n",
        "c2 = 1.5   # social\n"
      ],
      "metadata": {
        "id": "NTHPhjUeWggE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iteration in range(n_iterations):\n",
        "    for i in range(n_particles):\n",
        "        r1, r2 = np.random.rand(), np.random.rand()\n",
        "\n",
        "        velocities[i] = (\n",
        "            w * velocities[i]\n",
        "            + c1 * r1 * (pbest[i] - particles[i])\n",
        "            + c2 * r2 * (gbest - particles[i])\n",
        "        )\n",
        "\n",
        "        particles[i] += velocities[i]\n",
        "        particles[i] = np.clip(particles[i], 0, 1)\n",
        "\n",
        "        score = fitness_function(particles[i])\n",
        "\n",
        "        if score < pbest_scores[i]:\n",
        "            pbest[i] = particles[i]\n",
        "            pbest_scores[i] = score\n",
        "\n",
        "    gbest = pbest[np.argmin(pbest_scores)]\n",
        "    gbest_score = np.min(pbest_scores)\n",
        "\n",
        "    print(f\"Iteration {iteration+1}/{n_iterations}, Best fitness: {-gbest_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_p_Esd5WjSU",
        "outputId": "4cd4cace-770c-4885-beda-7282135893cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/30, Best fitness: 0.7537\n",
            "Iteration 2/30, Best fitness: 0.7537\n",
            "Iteration 3/30, Best fitness: 0.7537\n",
            "Iteration 4/30, Best fitness: 0.7537\n",
            "Iteration 5/30, Best fitness: 0.7662\n",
            "Iteration 6/30, Best fitness: 0.7779\n",
            "Iteration 7/30, Best fitness: 0.7779\n",
            "Iteration 8/30, Best fitness: 0.7779\n",
            "Iteration 9/30, Best fitness: 0.7779\n",
            "Iteration 10/30, Best fitness: 0.7779\n",
            "Iteration 11/30, Best fitness: 0.7779\n",
            "Iteration 12/30, Best fitness: 0.7779\n",
            "Iteration 13/30, Best fitness: 0.7779\n",
            "Iteration 14/30, Best fitness: 0.7779\n",
            "Iteration 15/30, Best fitness: 0.7779\n",
            "Iteration 16/30, Best fitness: 0.7779\n",
            "Iteration 17/30, Best fitness: 0.7779\n",
            "Iteration 18/30, Best fitness: 0.7779\n",
            "Iteration 19/30, Best fitness: 0.7779\n",
            "Iteration 20/30, Best fitness: 0.7779\n",
            "Iteration 21/30, Best fitness: 0.7779\n",
            "Iteration 22/30, Best fitness: 0.7779\n",
            "Iteration 23/30, Best fitness: 0.7779\n",
            "Iteration 24/30, Best fitness: 0.7779\n",
            "Iteration 25/30, Best fitness: 0.7779\n",
            "Iteration 26/30, Best fitness: 0.7779\n",
            "Iteration 27/30, Best fitness: 0.7779\n",
            "Iteration 28/30, Best fitness: 0.7779\n",
            "Iteration 29/30, Best fitness: 0.7779\n",
            "Iteration 30/30, Best fitness: 0.7779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_weights = gbest\n",
        "X_optimized = X * best_weights\n",
        "\n",
        "print(\"Optimized feature shape:\", X_optimized.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msrS0VUpWn10",
        "outputId": "a5079a8c-1e59-40e5-bdcb-f970c11e49d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized feature shape: (81, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_optimized.npy\", X_optimized)\n",
        "np.save(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/feature_weights_pso.npy\", best_weights)\n",
        "\n",
        "print(\"PSO optimized features saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGLP_521W0jY",
        "outputId": "3bbf1f55-c1c2-479f-abc2-44f9ad2c2971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO optimized features saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "metadata": {
        "id": "MavZJAIpXEtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_optimized.npy\")\n",
        "y = np.load(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/y_labels.npy\")\n",
        "\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpYHf2ZIXaGc",
        "outputId": "59e5bf52-7ef2-47a4-f038-f7c66a0e6871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(81, 29) (81,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8YMj63vXehw",
        "outputId": "4fce7fe6-97da-440b-bb0c-46031a5ce5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 29) (17, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "1IAr2wGxXhjz",
        "outputId": "0380d206-961c-4a93-fea1-b4d608f1dda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,033\u001b[0m (15.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,033</span> (15.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,033\u001b[0m (15.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,033</span> (15.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=8,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoxL9XESXkTA",
        "outputId": "1b9357fd-c270-4d48-eb09-e3a8defd380d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5747 - loss: 0.6950 - val_accuracy: 0.5294 - val_loss: 0.6699\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4363 - loss: 0.7505 - val_accuracy: 0.5294 - val_loss: 0.6403\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6095 - loss: 0.6766 - val_accuracy: 0.6471 - val_loss: 0.6220\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6255 - loss: 0.6068 - val_accuracy: 0.7059 - val_loss: 0.6041\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5928 - loss: 0.6703 - val_accuracy: 0.8235 - val_loss: 0.5859\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7266 - loss: 0.6143 - val_accuracy: 0.7647 - val_loss: 0.5717\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7953 - loss: 0.5731 - val_accuracy: 0.8235 - val_loss: 0.5576\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6239 - loss: 0.6092 - val_accuracy: 0.8235 - val_loss: 0.5466\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7175 - loss: 0.5727 - val_accuracy: 0.8235 - val_loss: 0.5379\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6897 - loss: 0.5708 - val_accuracy: 0.8235 - val_loss: 0.5329\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8319 - loss: 0.5108 - val_accuracy: 0.7647 - val_loss: 0.5261\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8232 - loss: 0.5584 - val_accuracy: 0.7647 - val_loss: 0.5236\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7459 - loss: 0.5413 - val_accuracy: 0.7647 - val_loss: 0.5210\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8853 - loss: 0.4510 - val_accuracy: 0.7647 - val_loss: 0.5204\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7976 - loss: 0.4649 - val_accuracy: 0.7647 - val_loss: 0.5195\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8871 - loss: 0.4092 - val_accuracy: 0.7647 - val_loss: 0.5179\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8337 - loss: 0.4209 - val_accuracy: 0.7647 - val_loss: 0.5164\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8130 - loss: 0.4666 - val_accuracy: 0.7059 - val_loss: 0.5187\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8050 - loss: 0.4814 - val_accuracy: 0.7059 - val_loss: 0.5181\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8313 - loss: 0.4261 - val_accuracy: 0.7059 - val_loss: 0.5208\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8838 - loss: 0.3273 - val_accuracy: 0.7059 - val_loss: 0.5253\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7565 - loss: 0.4784 - val_accuracy: 0.7059 - val_loss: 0.5284\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8245 - loss: 0.4607 - val_accuracy: 0.7059 - val_loss: 0.5274\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8241 - loss: 0.3890 - val_accuracy: 0.7059 - val_loss: 0.5296\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8390 - loss: 0.3335 - val_accuracy: 0.7059 - val_loss: 0.5309\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8215 - loss: 0.3681 - val_accuracy: 0.7059 - val_loss: 0.5362\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9354 - loss: 0.2858 - val_accuracy: 0.7059 - val_loss: 0.5402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models/voice_model.h5\")\n",
        "\n",
        "print(\"Voice model saved successfully\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liK8jaYnXn-o",
        "outputId": "bbe865d2-4bb2-46bd-fd36-1fcdf7369a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voice model saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models/voice_model.keras\")\n",
        "print(\"Model saved in recommended Keras format\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ58SlamX8_H",
        "outputId": "f446e04e-b773-4b6b-8896-624f75d959ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved in recommended Keras format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models/voice_model.keras\"\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "3Rb5IuvLYHuD",
        "outputId": "2e2cb3ca-6976-4abd-a340-03b11893c922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,068\u001b[0m (31.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,068</span> (31.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,033\u001b[0m (15.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,033</span> (15.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,035\u001b[0m (15.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,035</span> (15.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_optimized = np.load(\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_optimized.npy\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "v5Uq6rDXYYtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = model.predict(X_optimized[:1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st06mxOEYrUo",
        "outputId": "357a9189-a907-4810-8950-32f30ba4b1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models/voice_model.keras\"\n",
        ")\n",
        "\n",
        "print(\"Model loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsJK6KpGYvkf",
        "outputId": "a0cdc3df-1976-4611-da66-0bff0a1f49c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_optimized = np.load(\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_optimized.npy\"\n",
        ")\n",
        "\n",
        "print(\"Data shape:\", X_optimized.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5VUKA_8Y7Uz",
        "outputId": "f3afb5fd-77f1-4007-911c-c251a95f1d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (81, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_optimized[:1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WL7T-EhY9ul",
        "outputId": "371a6619-cea8-4500-cba8-5e47532f90aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.20505919]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "print(\"TensorFlow callbacks import works\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ6osbdFZEvy",
        "outputId": "83d42246-daef-44f7-8dc9-c6654fb62d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow callbacks import works\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models/voice_model.keras\"\n",
        ")\n",
        "print(\"Model loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYBkBkO0ZcCh",
        "outputId": "6acc752c-196c-4d32-cb36-094b99d469a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_optimized = np.load(\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_optimized.npy\"\n",
        ")\n",
        "print(\"Data shape:\", X_optimized.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th4nPYPIZpa9",
        "outputId": "5faa53c6-3543-451a-c709-7ea69854adb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (81, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = model.predict(X_optimized[:1])\n",
        "print(\"Model built\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hudj1XWZrsO",
        "outputId": "3d05a283-d4d9-4153-cc9e-b29de3573a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
            "Model built\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = model.predict(X_optimized[:1])\n",
        "print(\"Model built\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQyIT_9yZvgn",
        "outputId": "39dbff0e-fd76-4e28-ec5a-4b3ad92ad565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Model built\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "embedding_model = Model(\n",
        "    inputs=model.layers[0].input,   # 👈 KEY CHANGE\n",
        "    outputs=model.layers[-2].output\n",
        ")\n",
        "\n",
        "embedding_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "v9710WlsZ5kb",
        "outputId": "a8757aa1-5b3e-404a-a351-54d483508ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,000\u001b[0m (15.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> (15.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,000\u001b[0m (15.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> (15.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voice_embeddings = embedding_model.predict(X_optimized)\n",
        "print(\"Voice embedding shape:\", voice_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBfFwEmGZ7-s",
        "outputId": "e67f8185-3f7c-451a-b0e8-1b52daa54869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Voice embedding shape: (81, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\n",
        "    \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/voice_embeddings.npy\",\n",
        "    voice_embeddings\n",
        ")\n",
        "\n",
        "print(\"Voice embeddings saved successfully\")\n"
      ],
      "metadata": {
        "id": "i028cAEpaBDk",
        "outputId": "e3a794db-e8d9-44e1-afa9-444688db33a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voice embeddings saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6B: Voice Inference and Evaluation\n",
        "\n",
        "This section implements the inference (prediction) pipeline for the trained voice-based Parkinson’s disease detection model. The goal is to evaluate the trained model on unseen data and enable prediction on new voice samples.\n"
      ],
      "metadata": {
        "id": "gJEJ6rRNyDrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "import librosa\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "metadata": {
        "id": "bFWl5sUbx9bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxLjpdlb4H-M",
        "outputId": "77ef129e-337e-4c76-83df-1870382f4c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project\"\n",
        "\n",
        "print(\"Contents of project root:\")\n",
        "print(os.listdir(BASE_PATH))\n",
        "\n",
        "print(\"\\nContents of features folder:\")\n",
        "print(os.listdir(f\"{BASE_PATH}/features\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFFYtt875AhL",
        "outputId": "313b14aa-c0a7-470c-9374-e15de95b43e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of project root:\n",
            "['data', 'notebooks', 'features', 'models']\n",
            "\n",
            "Contents of features folder:\n",
            "['X_features.npy', 'y_labels.npy', 'X_normalized.npy', 'standard_scaler.pkl', 'X_optimized.npy', 'feature_weights_pso.npy', 'voice_embeddings.npy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "import librosa\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project\"\n",
        "\n",
        "# Load saved components\n",
        "scaler = joblib.load(f\"{BASE_PATH}/features/standard_scaler.pkl\")\n",
        "pso_weights = np.load(f\"{BASE_PATH}/features/feature_weights_pso.npy\")\n",
        "voice_model = load_model(f\"{BASE_PATH}/models/voice_model.keras\")\n",
        "\n",
        "print(\"Scaler, PSO weights, and voice model loaded successfully\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhvmmItE5P0D",
        "outputId": "af58a211-a911-4f33-f753-1bce2fc9d43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler, PSO weights, and voice model loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WIOiUTRL5h4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "\n",
        "\n",
        "def extract_mfcc(audio, sr, n_mfcc=13):\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc_var = np.var(mfcc, axis=1)\n",
        "    return np.hstack((mfcc_mean, mfcc_var))\n",
        "\n",
        "\n",
        "def extract_pitch(audio, sr):\n",
        "    pitch = librosa.yin(audio, fmin=75, fmax=300, sr=sr)\n",
        "    pitch = pitch[pitch > 0]\n",
        "    return np.mean(pitch) if len(pitch) > 0 else 0\n",
        "\n",
        "\n",
        "def extract_jitter_shimmer(audio_path):\n",
        "    sound = parselmouth.Sound(audio_path)\n",
        "    point_process = call(sound, \"To PointProcess (periodic, cc)\", 75, 300)\n",
        "    jitter = call(point_process, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "    shimmer = call([sound, point_process], \"Get shimmer (local)\",\n",
        "                    0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "    return jitter, shimmer\n",
        "\n",
        "\n",
        "def extract_voice_features(audio, sr, audio_path):\n",
        "    mfcc = extract_mfcc(audio, sr)\n",
        "    pitch = extract_pitch(audio, sr)\n",
        "    jitter, shimmer = extract_jitter_shimmer(audio_path)\n",
        "    return np.hstack([mfcc, pitch, jitter, shimmer])\n"
      ],
      "metadata": {
        "id": "BbLEEesy50k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praat-parselmouth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dlCl4Yk7Iw6",
        "outputId": "5f3b026c-0289-463d-a57c-c7b4b142fc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from praat-parselmouth) (2.0.2)\n",
            "Downloading praat_parselmouth-0.4.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/10.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/10.7 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m9.0/10.7 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "\n",
        "print(\"Parselmouth imported successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWcB28dD7kEO",
        "outputId": "d8a4bb81-bd8c-4cec-b3a8-f24818d3ae72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parselmouth imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzzOElKJ8AKn",
        "outputId": "bdcc206c-c74e-4df8-ad0a-d1c7c4c3f5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import joblib\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "print(\"All imports successful\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpjHiSY88trC",
        "outputId": "f4e5430b-eef3-4e2c-ba26-944c21d3942c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/IIIT_Nagpur_PD_Project\"\n",
        "print(\"Base path set\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hc7IPIF8w8p",
        "outputId": "fd685f49-6eeb-4629-f7ee-1d1301b3bcfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base path set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(audio, sr, n_mfcc=13):\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc_var = np.var(mfcc, axis=1)\n",
        "    return np.hstack((mfcc_mean, mfcc_var))\n",
        "\n",
        "\n",
        "def extract_pitch(audio, sr):\n",
        "    pitch = librosa.yin(audio, fmin=75, fmax=300, sr=sr)\n",
        "    pitch = pitch[pitch > 0]\n",
        "    return np.mean(pitch) if len(pitch) > 0 else 0\n",
        "\n",
        "\n",
        "def extract_jitter_shimmer(audio_path):\n",
        "    sound = parselmouth.Sound(audio_path)\n",
        "    point_process = call(sound, \"To PointProcess (periodic, cc)\", 75, 300)\n",
        "    jitter = call(point_process, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "    shimmer = call([sound, point_process], \"Get shimmer (local)\",\n",
        "                    0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "    return jitter, shimmer\n",
        "\n",
        "\n",
        "def extract_voice_features(audio, sr, audio_path):\n",
        "    mfcc = extract_mfcc(audio, sr)\n",
        "    pitch = extract_pitch(audio, sr)\n",
        "    jitter, shimmer = extract_jitter_shimmer(audio_path)\n",
        "    return np.hstack([mfcc, pitch, jitter, shimmer])\n",
        "\n",
        "print(\"Feature extraction functions ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvKZKAi388yX",
        "outputId": "3866825a-4a32-451f-a770-956aa1191036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction functions ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = joblib.load(f\"{BASE_PATH}/features/standard_scaler.pkl\")\n",
        "pso_weights = np.load(f\"{BASE_PATH}/features/feature_weights_pso.npy\")\n",
        "voice_model = load_model(f\"{BASE_PATH}/models/voice_model.keras\")\n",
        "\n",
        "print(\"Scaler, PSO weights, and model loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaWEyvTF8_fF",
        "outputId": "bee1fa5b-dcff-4e02-aeec-a4b134aa6a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler, PSO weights, and model loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_voice(wav_path):\n",
        "    # Load audio\n",
        "    audio, sr = librosa.load(wav_path, sr=16000, mono=True)\n",
        "    audio, _ = librosa.effects.trim(audio)\n",
        "\n",
        "    # Extract features\n",
        "    features = extract_voice_features(audio, sr, wav_path)\n",
        "    features = features.reshape(1, -1)\n",
        "\n",
        "    # Normalize\n",
        "    features_norm = scaler.transform(features)\n",
        "\n",
        "    # Apply PSO weights\n",
        "    features_opt = features_norm * pso_weights\n",
        "\n",
        "    # Predict PD probability\n",
        "    prob = voice_model.predict(features_opt, verbose=0)[0][0]\n",
        "\n",
        "    return prob\n",
        "\n",
        "print(\"predict_voice() function defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8kr83oQ9CKU",
        "outputId": "d6ba0eac-2014-4cd9-c06e-9bac9112409b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict_voice() function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_wav = f\"{BASE_PATH}/data/voice_dataset/PD/PD_AH/AH_545643618-82A143AC-B643-4273-A923-C42A83AEEC5F.wav\"\n",
        "\n",
        "prob = predict_voice(test_wav)\n",
        "\n",
        "print(f\"Predicted PD risk score: {prob:.4f}\")\n",
        "\n",
        "if prob >= 0.5:\n",
        "    print(\"High Parkinson’s risk\")\n",
        "else:\n",
        "    print(\"Low Parkinson’s risk\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l94FSV9G9FSn",
        "outputId": "ae54713e-35a2-4342-d9d0-c8b7eca0972f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted PD risk score: 0.3554\n",
            "Low Parkinson’s risk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV13BhCZpdLT",
        "outputId": "71c64ca3-7dae-4897-b6c0-5e5859c18b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILA5sRc2vq52",
        "outputId": "307ab5eb-6ac9-4fc9-94c3-4099fb0f765a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir('/content/drive/MyDrive')\n"
      ],
      "metadata": {
        "id": "zurbeb-y6yb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1213f74d-0585-43b9-99f2-d752c5e1184b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks',\n",
              " 'Classroom',\n",
              " 'Unit 1 - Matrices (6).gdoc',\n",
              " '2.Nature-based Solutions for Improving Human Well-being.docx',\n",
              " 'Business letter.gdoc',\n",
              " 'Product life cycle .key',\n",
              " 'fee p.jpg',\n",
              " 'EX 6.gdoc',\n",
              " 'APP.xlsx',\n",
              " 'stack using LINKEDLIST.gdoc',\n",
              " 'Stack using ARRAY (2).gdoc',\n",
              " 'Stack using ARRAY (1).gdoc',\n",
              " 'Stack using ARRAY.gdoc',\n",
              " 'MAIN PIC.jpg',\n",
              " 'DSA SHEET.gsheet',\n",
              " 'Research papers',\n",
              " 'Certificates',\n",
              " \"Sem Marksheet's\",\n",
              " 'Avinash',\n",
              " 'AWS AI-ML VIRTUAL INTERNSHIP (JAN - MAR 2025).pdf',\n",
              " 'Kerala instas',\n",
              " 'main days',\n",
              " 'RA2311026050074_M.Jijnash kumar.pdf',\n",
              " '(074), (199), _M. Jijnash Kumar, _K. Avinash.pdf',\n",
              " 'DAA MAIN.pdf',\n",
              " '(074), (199)_ M. Jijnash , K. Avinash.pdf',\n",
              " 'UHV (1).mp4',\n",
              " '(074), (199), M. Jijnash kumar, K. Avinash.pdf',\n",
              " 'Untitled document.gdoc',\n",
              " 'Research paper(074, 199) AIML_D.gdoc',\n",
              " 'Main Rough',\n",
              " 'Resume',\n",
              " 'GOOGLE CLOUD GENERATIVE-AI VIRTUAL INTERNSHIP.pdf',\n",
              " 'Community Connect Project Report Template (1) (1).rtf.gdoc',\n",
              " 'Community Connect Project Report Template (1).rtf.gdoc',\n",
              " '3.jpg',\n",
              " 'NGO',\n",
              " 'MongoDBBasicsforStudents_Badge20250801-30-ha36eb (1).pdf',\n",
              " 'MongoDBBasicsforStudents_Badge20250801-30-ha36eb.pdf',\n",
              " 'Phyton',\n",
              " \"PPT's\",\n",
              " 'Cloud 123.docx',\n",
              " 'Cloud 1.docx',\n",
              " 'Screenshot (88).png',\n",
              " 'Screenshot (89).png',\n",
              " 'IMG-20250819-WA0009.jpg',\n",
              " 'try to get information for the provided image.gsheet',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (9).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (8).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (7).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (6).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (5).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (4).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (3).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (2).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization (1).gdoc',\n",
              " 'A State-of-the-Art Review: Machine Learning Paradigms for Personalized Drug Recommendation and Therapeutic Optimization.gdoc',\n",
              " 'Screenshot (109).png',\n",
              " 'Screenshot 2025-08-28 183829.png',\n",
              " 'Untitled Diagram.drawio.png',\n",
              " 'Certificate - ServiceNow.pdf',\n",
              " 'Task4_CNAI.jpg',\n",
              " 'Task5_CNAI.jpg',\n",
              " 'Google AI Studio',\n",
              " 'no no, you are getting things wrong, like the ins....gsheet',\n",
              " 'for cloud model.docx',\n",
              " 'Gmail - 9th INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION (ICICC-2026) _ Submission (569) has been created..pdf',\n",
              " 'Shortlisted Paper Notification- ICICC 2026 for Paper ID 574.pdf',\n",
              " 'Screenshot_2025-11-10-11-23-45-060-edit_com.google (1).android.apps.nbu.files.jpg',\n",
              " 'Screenshot_2025-11-10-11-23-45-060-edit_com.google.android.apps.nbu.files.jpg',\n",
              " 'SOMETHING LIKE IIT BB',\n",
              " 'Web_Application_Screening_Task.docx (Converted - 2025-11-20 11:20) (1).gdoc',\n",
              " 'Web_Application_Screening_Task.docx (Converted - 2025-11-20 11:20).gdoc',\n",
              " 'FOSSEE IIT B',\n",
              " 'J IIJ.jpg',\n",
              " 'Gemini Export 9 December 2025 at 22:21:02 GMT+5:30.gdoc',\n",
              " 'Abstract 2026.pdf',\n",
              " 'mp1.pdf',\n",
              " 'solution proposal.pdf',\n",
              " 'mp1-merged.pdf',\n",
              " 'SRM Institute of Science and Technology Mail - Request for Mentorship and Guidance.pdf',\n",
              " 'IIIT_Nagpur_PD_Project']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/IIIT_Nagpur_PD_Project')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKY9QejvOK-o",
        "outputId": "1ff0539f-38cc-4889-8283-d2b372afcbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'notebooks', 'features', 'models']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C82YE6BuOVZR",
        "outputId": "f9cddb61-b4c9-4561-8b59-ad6bd448ea7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_features.npy',\n",
              " 'y_labels.npy',\n",
              " 'X_normalized.npy',\n",
              " 'standard_scaler.pkl',\n",
              " 'X_optimized.npy',\n",
              " 'feature_weights_pso.npy',\n",
              " 'voice_embeddings.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsrD_ATTOiZX",
        "outputId": "42b86d12-804f-4b48-8a11-51e02380f97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['voice_model.h5', 'voice_model.keras']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.load('/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_optimized.npy')\n",
        "y = np.load('/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/y_labels.npy')\n",
        "\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwbc2UHjOkGK",
        "outputId": "1b2bd6c2-4134-4375-8a4a-b8984704eaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(81, 29) (81,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "rQZIY012O4x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models/voice_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P802zpPBO8iD",
        "outputId": "6327fc62-46b6-4669-e374-75ceed3775ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = model.predict(X_test).ravel()\n",
        "\n",
        "# Binary predictions\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "print(\"ROC-AUC  :\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNOOtJHnO_Tj",
        "outputId": "83acab09-f608-4d58-b0ff-ec6e79b9bb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "Accuracy : 0.7647058823529411\n",
            "Precision: 0.75\n",
            "Recall   : 0.75\n",
            "F1 Score : 0.75\n",
            "ROC-AUC  : 0.8472222222222222\n",
            "\n",
            "Confusion Matrix:\n",
            " [[7 2]\n",
            " [2 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.load('/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/X_optimized.npy')\n",
        "y = np.load('/content/drive/MyDrive/IIIT_Nagpur_PD_Project/features/y_labels.npy')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "Q0xGD0k8PDfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "improved_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "improved_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUJglGWDPohH",
        "outputId": "516a472e-e06b-4d25-c108-40a8292cfd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = improved_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wfnOxq1PqaC",
        "outputId": "146a4bfb-0170-4f03-f068-3a88ab22087d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.6015 - loss: 0.7793 - val_accuracy: 0.5385 - val_loss: 0.6903\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4956 - loss: 0.9839 - val_accuracy: 0.4615 - val_loss: 0.6895\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5430 - loss: 0.8578 - val_accuracy: 0.4615 - val_loss: 0.6879\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6233 - loss: 0.7824 - val_accuracy: 0.4615 - val_loss: 0.6852\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6630 - loss: 0.5432 - val_accuracy: 0.5385 - val_loss: 0.6821\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4898 - loss: 0.7391 - val_accuracy: 0.6154 - val_loss: 0.6785\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7533 - loss: 0.5013 - val_accuracy: 0.6154 - val_loss: 0.6768\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5879 - loss: 0.7597 - val_accuracy: 0.6154 - val_loss: 0.6762\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6803 - loss: 0.6559 - val_accuracy: 0.6154 - val_loss: 0.6750\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6197 - loss: 0.6582 - val_accuracy: 0.6154 - val_loss: 0.6737\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7580 - loss: 0.5245 - val_accuracy: 0.6154 - val_loss: 0.6725\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7032 - loss: 0.5923 - val_accuracy: 0.6154 - val_loss: 0.6718\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7240 - loss: 0.5524 - val_accuracy: 0.6923 - val_loss: 0.6720\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8044 - loss: 0.5380 - val_accuracy: 0.6923 - val_loss: 0.6723\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6297 - loss: 0.6108 - val_accuracy: 0.6923 - val_loss: 0.6719\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5837 - loss: 0.6462 - val_accuracy: 0.6923 - val_loss: 0.6720\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7783 - loss: 0.4731 - val_accuracy: 0.6923 - val_loss: 0.6720\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8081 - loss: 0.4287 - val_accuracy: 0.6923 - val_loss: 0.6704\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7741 - loss: 0.4112 - val_accuracy: 0.6923 - val_loss: 0.6699\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7496 - loss: 0.4465 - val_accuracy: 0.6923 - val_loss: 0.6705\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7168 - loss: 0.5217 - val_accuracy: 0.6923 - val_loss: 0.6705\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8153 - loss: 0.4323 - val_accuracy: 0.6923 - val_loss: 0.6692\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7371 - loss: 0.4470 - val_accuracy: 0.6923 - val_loss: 0.6684\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7183 - loss: 0.4709 - val_accuracy: 0.6923 - val_loss: 0.6679\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7663 - loss: 0.4013 - val_accuracy: 0.6923 - val_loss: 0.6681\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7596 - loss: 0.4624 - val_accuracy: 0.6923 - val_loss: 0.6673\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7987 - loss: 0.4317 - val_accuracy: 0.6923 - val_loss: 0.6650\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7554 - loss: 0.5235 - val_accuracy: 0.6923 - val_loss: 0.6646\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7471 - loss: 0.4659 - val_accuracy: 0.6923 - val_loss: 0.6635\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7585 - loss: 0.5090 - val_accuracy: 0.6923 - val_loss: 0.6633\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7554 - loss: 0.5228 - val_accuracy: 0.6923 - val_loss: 0.6643\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7846 - loss: 0.5165 - val_accuracy: 0.6923 - val_loss: 0.6667\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6865 - loss: 0.4775 - val_accuracy: 0.6923 - val_loss: 0.6686\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8888 - loss: 0.3791 - val_accuracy: 0.6923 - val_loss: 0.6700\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7778 - loss: 0.4237 - val_accuracy: 0.6923 - val_loss: 0.6698\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8044 - loss: 0.4499 - val_accuracy: 0.6923 - val_loss: 0.6682\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8007 - loss: 0.4023 - val_accuracy: 0.6923 - val_loss: 0.6658\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8534 - loss: 0.3697 - val_accuracy: 0.6923 - val_loss: 0.6650\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9603 - loss: 0.2481 - val_accuracy: 0.6923 - val_loss: 0.6631\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8278 - loss: 0.3974 - val_accuracy: 0.6154 - val_loss: 0.6592\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8023 - loss: 0.3800 - val_accuracy: 0.6154 - val_loss: 0.6583\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8498 - loss: 0.3553 - val_accuracy: 0.6154 - val_loss: 0.6593\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8127 - loss: 0.3739 - val_accuracy: 0.6923 - val_loss: 0.6587\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8962 - loss: 0.3588 - val_accuracy: 0.6923 - val_loss: 0.6573\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8268 - loss: 0.4053 - val_accuracy: 0.6923 - val_loss: 0.6554\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7857 - loss: 0.4296 - val_accuracy: 0.6923 - val_loss: 0.6569\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8132 - loss: 0.3708 - val_accuracy: 0.6923 - val_loss: 0.6562\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7977 - loss: 0.4309 - val_accuracy: 0.6923 - val_loss: 0.6564\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8440 - loss: 0.3228 - val_accuracy: 0.6923 - val_loss: 0.6591\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9134 - loss: 0.2766 - val_accuracy: 0.6923 - val_loss: 0.6582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "improved_model.save(\n",
        "    '/content/drive/MyDrive/IIIT_Nagpur_PD_Project/models/voice_model_improved.keras'\n",
        ")\n"
      ],
      "metadata": {
        "id": "HKrg_QNOPsdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "y_prob = improved_model.predict(X_test).ravel()\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "print(\"ROC-AUC  :\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA4uX40GPza3",
        "outputId": "f7f06394-de7c-4733-c779-5d52f058dd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "Accuracy : 0.7647058823529411\n",
            "Precision: 0.75\n",
            "Recall   : 0.75\n",
            "F1 Score : 0.75\n",
            "ROC-AUC  : 0.7777777777777778\n",
            "\n",
            "Confusion Matrix:\n",
            " [[7 2]\n",
            " [2 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "thresholds = np.arange(0.2, 0.8, 0.05)\n",
        "\n",
        "print(\"Thresh | Precision | Recall | F1\")\n",
        "print(\"-\"*35)\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_t = (y_prob >= t).astype(int)\n",
        "    p = precision_score(y_test, y_pred_t)\n",
        "    r = recall_score(y_test, y_pred_t)\n",
        "    f = f1_score(y_test, y_pred_t)\n",
        "    print(f\"{t:.2f}   | {p:.2f}      | {r:.2f}  | {f:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBzU3YsoP1H-",
        "outputId": "61300651-6541-41f0-9655-605781052b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresh | Precision | Recall | F1\n",
            "-----------------------------------\n",
            "0.20   | 0.47      | 0.88  | 0.61\n",
            "0.25   | 0.58      | 0.88  | 0.70\n",
            "0.30   | 0.64      | 0.88  | 0.74\n",
            "0.35   | 0.64      | 0.88  | 0.74\n",
            "0.40   | 0.64      | 0.88  | 0.74\n",
            "0.45   | 0.64      | 0.88  | 0.74\n",
            "0.50   | 0.75      | 0.75  | 0.75\n",
            "0.55   | 0.71      | 0.62  | 0.67\n",
            "0.60   | 0.83      | 0.62  | 0.71\n",
            "0.65   | 0.83      | 0.62  | 0.71\n",
            "0.70   | 0.75      | 0.38  | 0.50\n",
            "0.75   | 1.00      | 0.38  | 0.55\n",
            "0.80   | 1.00      | 0.25  | 0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5U13IGviQWYi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}